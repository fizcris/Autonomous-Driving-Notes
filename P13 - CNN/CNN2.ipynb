{
 "cells": [
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "f27a025a",
=======
   "id": "f552a987",
>>>>>>> a2136ba4d0923dc1dc741f2a566f723db6e39856
   "metadata": {},
   "source": [
    "## Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "09d52424",
=======
   "id": "373c04d2",
>>>>>>> a2136ba4d0923dc1dc741f2a566f723db6e39856
   "metadata": {},
   "source": [
    "* input layer has a width of W and a height of `H`\n",
    "* convolutional layer has a filter size `F`\n",
    "* stride of `S`\n",
    "* padding of `P`\n",
    "* number of filters `K`,\n",
    "\n",
    "```\n",
    "W_out =[ (Wâˆ’F+2P)/S] + 1.\n",
    "H_out = [(H-F+2P)/S] + 1.\n",
    "D_out = K.\n",
    "W_out * H_out * D_out.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
<<<<<<< HEAD
   "id": "2007ba92",
=======
   "id": "ca423cdd",
>>>>>>> a2136ba4d0923dc1dc741f2a566f723db6e39856
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height: 14.0. width: 14.0\n"
     ]
    }
   ],
   "source": [
    "input_height = 32\n",
    "input_width = 32\n",
    "\n",
    "filter_height = 8\n",
    "filter_width = 8\n",
    "\n",
    "P = 1\n",
    "S = 2\n",
    "\n",
    "new_height = (input_height - filter_height + 2 * P)/S + 1\n",
    "new_width = (input_width - filter_width + 2 * P)/S + 1\n",
    "\n",
    "\n",
    "print(\"height: {}. width: {}\".format(new_height,new_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
<<<<<<< HEAD
   "id": "eafcec38",
=======
   "id": "719a797a",
>>>>>>> a2136ba4d0923dc1dc741f2a566f723db6e39856
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "input = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "filter_weights = tf.Variable(tf.truncated_normal((8, 8, 3, 20))) # (height, width, input_depth, output_depth)\n",
    "filter_bias = tf.Variable(tf.zeros(20))\n",
    "strides = [1, 2, 2, 1] # (batch, height, width, depth)\n",
    "padding = 'SAME'\n",
    "conv = tf.nn.conv2d(input, filter_weights, strides, padding) + filter_bias"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "4da2547f",
=======
   "id": "c0d599da",
>>>>>>> a2136ba4d0923dc1dc741f2a566f723db6e39856
   "metadata": {},
   "source": [
    "### For TensorFlow\n",
    "\n",
    "SAME Padding, the output height and width are computed as:\n",
    "\n",
    "out_height = ceil(float(in_height) / float(strides[1]))\n",
    "\n",
    "out_width = ceil(float(in_width) / float(strides[2]))\n",
    "\n",
    "VALID Padding, the output height and width are computed as:\n",
    "\n",
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "\n",
    "out_width = ceil(float(in_width - filter_width + 1) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
<<<<<<< HEAD
   "id": "d40be80d",
=======
   "id": "15d4d40c",
>>>>>>> a2136ba4d0923dc1dc741f2a566f723db6e39856
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756560"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8 * 8 * 3 + 1) * (14 * 14 * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
<<<<<<< HEAD
   "id": "95a28370",
=======
   "id": "35f93fed",
>>>>>>> a2136ba4d0923dc1dc741f2a566f723db6e39856
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3860"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8 * 8 * 3 + 1) *20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
<<<<<<< HEAD
   "id": "436eb654",
=======
   "id": "86da9125",
>>>>>>> a2136ba4d0923dc1dc741f2a566f723db6e39856
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
   "id": "4e535102",
   "metadata": {},
   "outputs": [],
   "source": [
    " new_height = (input_height - filter_height + 2 * P)/S + 1\n",
    " new_width = (input_width - filter_width + 2 * P)/S + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2e577e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "# Input Properties\n",
    "color_channels = 1\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 2\n",
    "filter_size_height = 2\n",
    "\n",
    "# Output depth\n",
    "k_output = 3\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "# output = conv2d(X)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69dc4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input_array):\n",
    "    # Filter (weights and bias)\n",
    "    F_W = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "    F_b = tf.Variable(tf.zeros(k_output))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input_array, F_W, strides, padding) + F_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce983cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool(input):\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acb7ef3",
   "metadata": {},
   "source": [
    "```\n",
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "out_height = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "out_width  = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dbc6474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height: 10.0, width: 10.0\n"
     ]
    }
   ],
   "source": [
    "in_height = 14\n",
    "in_width = 14\n",
    "\n",
    "filter_height = 5\n",
    "filter_width = 5\n",
    "\n",
    "strides = [1, 1, 1, 1]\n",
    "\n",
    "out_height = np.ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "out_width  = np.ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "\n",
    "print(\"height: {}, width: {}\".format(out_height,out_width))"
   ]
=======
   "execution_count": null,
   "id": "a5730d9e",
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> a2136ba4d0923dc1dc741f2a566f723db6e39856
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
