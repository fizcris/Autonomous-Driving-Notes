{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b1a314-8003-4a9f-9928-40c0dd52592a",
   "metadata": {},
   "source": [
    "# Intro to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab0732f-38ba-4938-ad89-4bec6401b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Create TensorFlow object called hello_constant\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53bf1684-5d12-4c01-b5f5-fc78acb9875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8412c0-2b4e-4b36-b160-55b322eb0c52",
   "metadata": {},
   "source": [
    "## Sessionâ€™s feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20657923-8b54-42fb-9173-47cdbcfd0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "output = None\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518077e4-f7da-4fae-bdc1-0d32e185ba7e",
   "metadata": {},
   "source": [
    "## Math"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f1134ac-12fa-48c2-844c-3547cb9247ef",
   "metadata": {},
   "source": [
    "x = tf.add(5, 2)  # 7\n",
    "x = tf.subtract(10, 4) # 6\n",
    "y = tf.multiply(2, 5)  # 10\n",
    "\n",
    "tf.subtract(tf.constant(2.0),tf.constant(1))  # Fails with ValueError: Tensor conversion requested dtype float32 for Tensor with dtype int32: \n",
    "tf.subtract(tf.cast(tf.constant(2.0), tf.int32), tf.constant(1))   # 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f12661de-18a6-4312-9390-b7a690c760cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = tf.subtract(tf.divide(x,y),tf.cast(tf.constant(1), tf.float64))\n",
    "z = tf.subtract(tf.divide(x,y),tf.cast(tf.constant(1), tf.float64))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0087a2-3bcc-4c70-8645-8d99ad905ed1",
   "metadata": {},
   "source": [
    "The `tf.Variable` class creates a tensor with an initial value that can be modified, much like a normal Python variable. This tensor stores its state in the session, so you must initialize the state of the tensor manually. You'll use the `tf.global_variables_initializer()` function to initialize the state of all the Variable tensors.\n",
    "\n",
    "The `tf.global_variables_initializer()` call returns an operation that will initialize all TensorFlow variables from the graph. You call the operation using a session to initialize all the variables as shown above. Using the `tf.Variable` class allows us to change the weights and bias, but an initial value needs to be chosen.\n",
    "\n",
    "Initializing the weights with random numbers from a normal distribution is good practice. Randomizing the weights helps the model from becoming stuck in the same place every time you train it\n",
    "\n",
    "Similarly, choosing weights from a normal distribution prevents any one weight from overwhelming other weights. You'll use the `tf.truncated_normal()` function to generate random numbers from a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b7ac1-e015-406d-b9be-f2cf7f645bff",
   "metadata": {},
   "source": [
    "## `tf.truncated_normal()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11ab175d-cca9-4a7c-9aab-58014809789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 120\n",
    "n_labels = 5\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd75d248-3aa6-45e4-a696-7e558729c8d4",
   "metadata": {},
   "source": [
    "## `tf.zeros()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "804061f6-7d10-4b55-b77e-ae11da9e6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 5\n",
    "bias = tf.Variable(tf.zeros(n_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87230ceb-4fed-493d-9bd6-9d33631c82ac",
   "metadata": {},
   "source": [
    "## Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ecf708e-f427-496a-94ce-b61995e5ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(n_features, n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow weights\n",
    "    :param n_features: Number of features\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow weights\n",
    "    \"\"\"\n",
    "    return tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "\n",
    "\n",
    "def get_biases(n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow bias\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow bias\n",
    "    \"\"\"\n",
    "    return tf.zeros(n_labels)\n",
    "\n",
    "\n",
    "def linear(input, w, b):\n",
    "    \"\"\"\n",
    "    Return linear function in TensorFlow\n",
    "    :param input: TensorFlow input\n",
    "    :param w: TensorFlow weights\n",
    "    :param b: TensorFlow biases\n",
    "    :return: TensorFlow linear function\n",
    "    \"\"\"\n",
    "    # TODO: Linear Function (xW + b)\n",
    "    return tf.add(tf.matmul(input,w),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0266e473-399e-4e76-bc9b-9b60fa61908f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images[:10000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b821928-62d7-4888-9c2b-f7f477527812",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[0] mismatch In[1] shape: 28 vs. 784: [10000,28,28] [784,3] 0 0\n\t [[node MatMul_1 (defined at <ipython-input-2-620948cd2247>:29) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node MatMul_1:\n Placeholder_4 (defined at <ipython-input-5-2813205be238>:29)\t\n Variable_1/read (defined at <ipython-input-2-620948cd2247>:8)\n\nOriginal stack trace for 'MatMul_1':\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-2813205be238>\", line 37, in <module>\n    logits = linear(features, w, b)\n  File \"<ipython-input-2-620948cd2247>\", line 29, in linear\n    return tf.add(tf.matmul(input,w),b)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 3216, in matmul\n    return gen_math_ops.batch_mat_mul_v2(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1560, in batch_mat_mul_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 742, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3477, in _create_op_internal\n    ret = Operation(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1949, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1440\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1441\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: In[0] mismatch In[1] shape: 28 vs. 784: [10000,28,28] [784,3] 0 0\n\t [[{{node MatMul_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2813205be238>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# Run optimizer and get loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     _, l = session.run(\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         feed_dict={features: train_features, labels: train_labels})\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1181\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1359\u001b[0m                            run_metadata)\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: In[0] mismatch In[1] shape: 28 vs. 784: [10000,28,28] [784,3] 0 0\n\t [[node MatMul_1 (defined at <ipython-input-2-620948cd2247>:29) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node MatMul_1:\n Placeholder_4 (defined at <ipython-input-5-2813205be238>:29)\t\n Variable_1/read (defined at <ipython-input-2-620948cd2247>:8)\n\nOriginal stack trace for 'MatMul_1':\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-2813205be238>\", line 37, in <module>\n    logits = linear(features, w, b)\n  File \"<ipython-input-2-620948cd2247>\", line 29, in linear\n    return tf.add(tf.matmul(input,w),b)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 3216, in matmul\n    return gen_math_ops.batch_mat_mul_v2(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1560, in batch_mat_mul_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 742, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3477, in _create_op_internal\n    ret = Operation(\n  File \"C:\\ProgramData\\Anaconda3\\envs\\IntroToTensorFlow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1949, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Solution is available in the other \"quiz_solution.ipynb\" tab\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "def mnist_features_labels(n_labels):\n",
    "    \"\"\"\n",
    "    Gets the first <n> labels from the MNIST dataset\n",
    "    :param n_labels: Number of labels to use\n",
    "    :return: Tuple of feature list and label list\n",
    "    \"\"\"\n",
    "    mnist_features = []\n",
    "    mnist_labels = []\n",
    "\n",
    "    (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    mnist_features = train_images[:10000]\n",
    "    mnist_labels = train_labels[:10000]\n",
    "\n",
    "    return mnist_features, mnist_labels\n",
    "\n",
    "\n",
    "# Number of features (28*28 image is 784 features)\n",
    "n_features = 784\n",
    "# Number of labels\n",
    "n_labels = 3\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# Weights and Biases\n",
    "w = get_weights(n_features, n_labels)\n",
    "b = get_biases(n_labels)\n",
    "\n",
    "# Linear Function xW + b\n",
    "logits = linear(features, w, b)\n",
    "\n",
    "# Training data\n",
    "train_features, train_labels = mnist_features_labels(n_labels)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Softmax\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    # Cross entropy\n",
    "    # This quantifies how far off the predictions were.\n",
    "    # You'll learn more about this in future lessons.\n",
    "    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "    # Training loss\n",
    "    # You'll learn more about this in future lessons.\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    # Rate at which the weights are changed\n",
    "    # You'll learn more about this in future lessons.\n",
    "    learning_rate = 0.08\n",
    "\n",
    "    # Gradient Descent\n",
    "    # This is the method used to train the model\n",
    "    # You'll learn more about this in future lessons.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Run optimizer and get loss\n",
    "    _, l = session.run(\n",
    "        [optimizer, loss],\n",
    "        feed_dict={features: train_features, labels: train_labels})\n",
    "\n",
    "# Print loss\n",
    "print('Loss: {}'.format(l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070f2a6c-b72b-4ff5-a22a-2aafe46631db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063227ad-f597-4772-92e2-b8879b202588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8360188  0.11314284 0.05083836]\n"
     ]
    }
   ],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    # TODO: Compute and return softmax(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "logits = [3.0, 1.0, 0.2]\n",
    "print(softmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8313f77-fe9d-4ab2-9eec-6e1e2250b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.nn.softmax([2.0, 1.0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "736b742c-f142-4796-94fc-ddbf75db4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution is available in the other \"solution.ipynb\" \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def run():\n",
    "    output = None\n",
    "    logit_data = [0.2, 0.1, .001]\n",
    "    logits = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # TODO: Calculate the softmax of the logits\n",
    "    softmax =  tf.nn.softmax(logits)   \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        pass\n",
    "        # TODO: Feed in the logit data\n",
    "        output = sess.run(softmax,\n",
    "                          feed_dict ={logits:logit_data}  )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb08b9c1-2b25-4685-95be-75469c668435",
   "metadata": {},
   "source": [
    "# Mini batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb475c1-1511-4a80-8323-a14d1dc3eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c3e0f-896d-4c15-b38d-3ae8bc41728d",
   "metadata": {},
   "source": [
    "The None dimension is a placeholder for the batch size. At runtime, TensorFlow will accept any batch size greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5421f6b5-2aeb-4b77-8840-90ffd9c620d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    outout_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba397a10-83db-4563-bec4-04dde4bf1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from helper import batches\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "# TODO: Set batch size\n",
    "batch_size = 128\n",
    "assert batch_size is not None, 'You must set the batch size'\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # TODO: Train optimizer on all batches\n",
    "    for batch_features, batch_labels in batches(batch_size, train_features, train_labels):\n",
    "        sess.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92af5cd-3304-46ca-8c1a-069317eccee3",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd826030-2b8a-4a57-9a20-bb33f56b1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_grayscale(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
